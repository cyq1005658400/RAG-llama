{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce9774d-3ed5-485e-9f59-f4737bbcbe63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:13:50.746124Z",
     "iopub.status.busy": "2024-11-12T17:13:50.745783Z",
     "iopub.status.idle": "2024-11-12T17:14:09.654786Z",
     "shell.execute_reply": "2024-11-12T17:14:09.654251Z",
     "shell.execute_reply.started": "2024-11-12T17:13:50.746100Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/site-packages (0.11.23)\n",
      "Requirement already satisfied: llama-index-llms-huggingface in /usr/local/lib/python3.10/site-packages (0.3.5)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.3.4)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.23 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.11.23)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.2.5)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.2.16)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.2.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in /usr/local/lib/python3.10/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from llama-index-llms-huggingface) (0.23.5)\n",
      "Requirement already satisfied: text-generation<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/site-packages (from llama-index-llms-huggingface) (0.7.0)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/site-packages (from llama-index-llms-huggingface) (2.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.46.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/site-packages (from ipywidgets) (8.28.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.12.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/site-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.52.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.23->llama-index) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.2.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.16.0)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in /usr/local/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index) (0.1.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/site-packages (from llama-index-readers-file<0.4.0,>=0.3.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.10/site-packages (from llama-index-readers-file<0.4.0,>=0.3.0->llama-index) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/site-packages (from llama-index-readers-file<0.4.0,>=0.3.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index) (0.5.13)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.6.77)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.20.3)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (1.0.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (6.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (4.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.4.0,>=0.3.0->llama-index) (2.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.0.6)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (0.6.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.23->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.23->llama-index) (3.23.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (0.2.0)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/site-packages (4.46.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/site-packages (from transformers) (0.23.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "2024-11-13 01:14:08.017423: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-13 01:14:08.291768: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-13 01:14:09.165687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index llama-index-llms-huggingface ipywidgets\n",
    "!pip install transformers -U\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import torch\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from modelscope import snapshot_download\n",
    "from llama_index.core.base.embeddings.base import BaseEmbedding, Embedding\n",
    "from abc import ABC\n",
    "from typing import Any, List, Optional, Dict, cast\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    "    set_global_service_context,\n",
    "    SimpleDirectoryReader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b10319b-6152-4180-bf3b-08a7ae7dbc1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:14:14.522966Z",
     "iopub.status.busy": "2024-11-12T17:14:14.522255Z",
     "iopub.status.idle": "2024-11-12T17:14:49.691204Z",
     "shell.execute_reply": "2024-11-12T17:14:49.690609Z",
     "shell.execute_reply.started": "2024-11-12T17:14:14.522932Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1958b8ad0c458b8c56bd234e666e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Model names \n",
    "qwen2_4B_CHAT = \"qwen/Qwen1.5-4B-Chat\"\n",
    "\n",
    "selected_model = snapshot_download(qwen2_4B_CHAT)\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant.\n",
    "\"\"\"\n",
    "\n",
    "query_wrapper_prompt = PromptTemplate(\n",
    "    \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST] \"\n",
    ")\n",
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=2048,\n",
    "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=selected_model,\n",
    "    model_name=selected_model,\n",
    "    device_map=\"auto\",\n",
    "    # change these settings below depending on your GPU\n",
    "    model_kwargs={\"torch_dtype\": torch.float16},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c70de82-e014-4db8-b534-89cbbe122f2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:14:59.787302Z",
     "iopub.status.busy": "2024-11-12T17:14:59.786993Z",
     "iopub.status.idle": "2024-11-12T17:15:00.554344Z",
     "shell.execute_reply": "2024-11-12T17:15:00.553573Z",
     "shell.execute_reply.started": "2024-11-12T17:14:59.787283Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-13 01:15:00--  https://modelscope.oss-cn-beijing.aliyuncs.com/resource/rag/xianjiaoda.md\n",
      "正在解析主机 modelscope.oss-cn-beijing.aliyuncs.com (modelscope.oss-cn-beijing.aliyuncs.com)... 121.89.3.244\n",
      "正在连接 modelscope.oss-cn-beijing.aliyuncs.com (modelscope.oss-cn-beijing.aliyuncs.com)|121.89.3.244|:443... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 200 OK\n",
      "长度： 13228 (13K) [text/markdown]\n",
      "正在保存至: ‘data/xianjiaoda/xianjiaoda.md’\n",
      "\n",
      "data/xianjiaoda/xia 100%[===================>]  12.92K  --.-KB/s    用时 0s      \n",
      "\n",
      "2024-11-13 01:15:00 (32.7 MB/s) - 已保存 ‘data/xianjiaoda/xianjiaoda.md’ [13228/13228])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id_='1695a1b3-60f1-4e24-8325-426a7cce95ee', embedding=None, metadata={'file_path': '/mnt/workspace/data/xianjiaoda/xianjiaoda.md', 'file_name': 'xianjiaoda.md', 'file_type': 'text/markdown', 'file_size': 13228, 'creation_date': '2024-11-13', 'last_modified_date': '2024-01-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='西安交通大学是我国最早兴办、享誉海内外的著名高等学府，是教育部直属重点大学。西迁以来，一代代交大人扎根西部、服务国家，为西部发展和国家建设作出了卓越贡献，以实际行动铸就了第一批纳入中国共产党人精神谱系的西迁精神。2017年12月，习近平总书记对学校15位老教授来信作出重要指示。在2018年新年贺词中，习近平总书记再次提到“西安交大西迁的老教授”。2020年4月22日，习近平总书记来校考察并发表重要讲话，强调西迁精神的核心是爱国主义，精髓是听党指挥跟党走，与党和国家、与民族和人民同呼吸、共命运，勉励师生在新时代创造属于我们这代人的历史功绩，给全校师生以巨大关怀和极大鼓舞，为学校新时代建设中国特色世界一流大学提供了根本遵循和行动指南。\\n\\n十九世纪末，甲午战败，民族危难。近代著名实业家、教育家盛宣怀秉持“自强首在储才，储才必先兴学”的信念，于1896年在上海创建了南洋公学，1921年定名为交通大学。学校坚持“求实学、务实业”办学宗旨，强调“修一等品行、求一等学问、创一等事业、成一等人才”办学目标。至二十世纪二三十年代，成为独具“理工管”特色的著名大学。抗战时期，学校移至租界，内迁重庆，坚持沪渝两地办学，为抵御外侮，不少学生投笔从戎，浴血沙场。解放前夕，师生积极投入民主革命和解放斗争，学校被誉为“民主堡垒”。\\n1955年中央决定交通大学内迁西安；1956年起师生分批迁赴西安；1957年分设为交通大学西安、上海两个部分，实行统一领导；1959年，交通大学西安部分定名为西安交通大学，同年被列为全国十六所重点大学之一。2000年国务院决定将西安交通大学、西安医科大学、陕西财经学院三校合并，组建新的西安交通大学。\\n\\n学校是“七五”“八五”重点建设单位，首批进入国家“211”和“985”工程建设学校。2017 年入选国家一流大学建设名单 A 类建设高校，2022 年入选国家第二轮“双一流”建设高校，8 个学科入选“双一流”建设学科。据 ESI 公布的数据，截至 2023 年 5 月，学校 17 个学科进入世界学术机构前 1%，5 个学科进入前 1‰，其中工程学进入前万分之一。\\n\\n学校是涵盖理、工、医、经、管、文、法、哲、艺、教育、交叉等11个学科门类的综合性研究型大学，设有32个学院（部、中心）、9个本科书院和3所直属附属医院。现有在编教工6635人，其中专任教师3789人。师资队伍中入选院士、杰青等国家级各类重大人才工程545人次，获评国家级各类创新团队51个，为国家作出突出贡献并享受政府特殊津贴专家450名，国家级教学名师11名。\\n\\n学校现有学生54760名，其中本科生22407名，研究生29285名，留学生3068名；本科招生专业76个、博士学位授权一级学科36个、硕士学位授权一级学科43个、博士专业学位授权点6个、硕士专业学位授权点29个，博士后流动站30个，国家一级重点学科8个、国家二级重点学科8个、国家重点（培育）学科3个，全国（国家）重点实验室8个，国家工程（技术）研究中心10个，国家产教融合创新平台2个，国家国际科技合作基地5个，国家应用数学中心1个，2011协同创新中心1个、其他省部级及以上重点科研基地195个。\\n\\n建校127年来，形成了兴学强国、艰苦创业、崇德尚实、严谨治学的优良传统，起点高、基础厚、要求严、重实践的办学特色，培养出了一大批卓越的政治家、科学家、社会活动家、教育家、企业家、艺术家、医学专家等，如蔡锷、张元济、蔡元培、黄炎培、邵力子、李叔同、邹韬奋、陆定一、钱学森、张光斗、汪道涵、吴文俊、杨嘉墀、徐光宪、姚桐斌、陈能宽、江泽民、侯宗濂、黄旭华、顾诵芬、丁关根、吴自良、蒋新松、蒋正华、王希季、李金华、韩启德等。建校以来，有200余名交大校友当选“两院”院士；迁校以来，学校培养或在校工作的院士89名。有6位“两弹一星”功勋奖章获得者、4位国家最高科技奖获得者、3位新中国“最美奋斗者”、2位“共和国勋章”和国家荣誉称号获得者、10位世界500强中国企业掌门人。近五年国家科学技术奖获得者168人，全国劳动模范、全国先进工作者、全国五一劳动奖章获得者75人。迁校以来，学校为国家输送了各类人才29万余名。\\n\\n学校建立思政引领、品行养成、知识传授、能力培养、思维创新“五位一体”育人模式，建立“通识教育+宽口径专业教育”、本-硕-博贯通的人才培养模式，构建产教深度融合的专业型人才培养模式，实施“百千万卓越工程人才培养”计划，打破学科壁垒，积极探索高端人才培养新路径，提升人才培养质量。\\n\\n2006年，学校实行书院、学院“双院制”培养模式，在全国率先探索“党建引领、知行兼修、师生共处、因材施教”的“一站式”学生社区综合管理服务，2019年获批教育部“一站式”学生社区综合管理模式建设首批试点高校。坚持探索拔尖创新人才培养，从1985年开始招收少年班学生；随后开办钱学森班、侯宗濂医学试验班、人工智能试验班、储能班；以钱学森学院为载体，数学、物理学、计算机科学、力学、基础医学入选教育部基础学科拔尖学生培养计划2.0，以培养具有全球视野和科学家素养的行业领军人才为目标来建设和管理各类试验班，把钱学森精神和智慧运用到教育教学实践中。\\n\\n学校61个专业入选国家级一流本科专业建设点，获国家级教学成果奖78项，入选教育部虚拟教研室建设试点11个，建成国家级一流本科课程129门，拥有8个国家级教学（人才培养）基地、12个国家级实验教学示范中心（含虚拟仿真实验教学中心）、9个国家级教学团队，获“全国百篇优秀博士论文奖”27篇、提名奖46篇。\\n\\n2000年至今，学校牵头承担国家科技重大专项、国家重点研发计划和基地与人才专项等重大项目数百项，获批国家自然科学基金项目6985项，基础研究项目数和经费在全国高校位居前列。承担文科国家级重大科研项目49项，获得教育部人文社科奖36项，与政府、企业等共建25个高端智库，一大批研究成果被采纳应用。\\n\\n学校医学教育事业发展迅速，以服务人民生命健康需求为导向，以国家医学中心建设为契机，以新医科建设为抓手，以医工交叉为突破点，加速促进医工、医理、医文交叉融合，推进基础医学与临床医学、临床医学与预防医学、医学学科与其他学科交叉融合，加快推进医学前沿研究，构建具有交大特色和示范效应的医学教育新体系，推动附属医院高质量发展，实现医学学科突破发展，建成一流医学学科，服务健康中国建设。\\n\\n进入新时代，学校主动把握世界高等教育规律，适应新一轮科技革命和产业变革需要，以“国家使命担当、全球科教高地、服务陕西引擎、创新驱动平台、智慧学镇示范”为目标定位，创建中国西部科技创新港，围绕理、工、医、文4大领域建立了8大平台、30个研究院和400多个科研基地、智库，深入推进教研一体、学科交叉、产教融合、协同育人、联合攻关，通过先行先试、破题示范，主动探索21世纪现代大学与社会发展深度融合的新模式、新形态和新经验，打造服务新时代西部大开发形成新格局的创新引擎。\\n\\n学校坚持“四个面向”，不断增强科技创新能力。迁校以来，创造了百余项国内外科学研究领域的“第一”，在抢占科研制高点方面发挥了交大的引领作用，其中包括创建了我国第一个工程热物理研究所，第一个汽轮机、汽车制造、制冷与低温和压缩机专业，研制出我国第一台大型通用电子计算机、首个自主知识产权的数字处理芯片，在国际上首次提出了双剪统一强度理论等。\\n\\n迁校以来，学校创造了30000余项科研成果，其中241项获得国家三大奖，产生了数以千亿计的经济社会效益。学校依托学科与人才培养优势，创新产学研合作模式，与政府、大中型企业联合建立研发中心，注重解决行业关键性技术问题，充分发挥科技对区域经济和社会发展的支撑作用。\\n\\n学校以社会主义核心价值观为引领，弘扬西迁精神，深入实施文化强校战略，坚持人文与科学并重，构建“塑心、育行、绘象、造境”文化建设格局和全方位文化育人体系，以“文化+”激活基层“文化细胞”，营造风清气正的政治文化、求实创新的学术文化、宽厚包容的人文文化，打造特色鲜明的体育文化、美育文化、劳动文化，促进学生德智体美劳全面发展。“大先生”系列话剧、金色梧桐节等一批文化品牌深入人心。获评全国文明校园、全国高校“礼敬中华优秀传统文化”十大示范项目、首批中华优秀传统文化传承基地等。\\n\\n学校拥有国家大学生文化素质教育基地和156个学生社团，科技、文艺、体育等活动丰富多彩，“九州名家”“纵论四海”“新港报告”“创源论坛”等成为师生开拓视野的经典品牌。历年来，交大学子在SAE国际航空设计大赛、VEX机器人世界锦标赛、国际数学建模大赛、世界华语辩论锦标赛、国际英语演讲大赛、世界大学生建筑设计竞赛、世界大学生赛艇锦标赛、ACM国际大学生程序设计大赛亚洲区选拔赛、中国“互联网+”大学生创新创业大赛、中国研究生创新实践系列大赛、“挑战杯”全国大学生课外科技作品竞赛、“挑战杯”全国大学生创业计划大赛、全国大学生数学建模大赛、全国大学生机械创新设计大赛、Robocon全国大学生机器人大赛、中国大学生物理学术竞赛、全国航空航天模型（科研类）锦标赛、全国大学生节能减排与社会实践科技竞赛等国际国内大赛中屡获佳绩。\\n\\n学校高度重视国际合作与交流，秉承为世界之光的传统，扎根中国大地建设世界一流大学。近年来，实施全球校园计划，通过联合培养、学生交换等多种形式，培养具有全球视野的拔尖创新人才。与世界一流大学开展深度合作，不断探索合作新模式，创办西交利物浦大学、西安交通大学米兰理工联合设计与创新学院等一批中外合作办学机构与项目。通过举办海外友好高校校园日、诺奖学者校园行、为世界之光大讲堂等，营造国际化校园氛围。服务共建“一带一路”，首倡发起丝绸之路大学联盟，已经吸引37个国家和地区的160余所大学加盟并开展多元合作。开放融合开展国际科技合作，为解决世界性重大科学难题贡献中国智慧、提出中国方案、发出中国声音。\\n\\n学校现有兴庆、雁塔、曲江和中国西部科技创新港4个校区，占地面积约5000亩，各类建筑总面积约400万平方米。1995年5月4日，学校图书馆被中共中央宣传部批准命名为“钱学森图书馆”。同年，时任国家主席江泽民为之题写了馆名。学校图书馆现由兴庆校区钱学森图书馆，雁塔校区图书馆和创新港图书资料中心三部分组成，总建筑面积43794平方米，阅览座位 3963 席，设有满足多种需求的学习研讨空间。馆藏文献资源丰富，累计藏书 589.7万册 (件)引进国内外电子资源 143 个平台约 350个子库。拥有中外文全文电子期刊 7.9 万余种，中西文电子图书 232.6 万余种。\\n\\n在新的历史起点上，学校将高举习近平新时代中国特色社会主义思想伟大旗帜，全面贯彻习近平总书记来校考察重要讲话精神，牢记为党育人、为国育才使命，落实立德树人根本任务，胸怀“国之大者”，弘扬西迁精神，勇担国家使命，共创交大荣誉，加快建设中国特色世界一流大学，以实际行动坚决拥护“两个确立”、坚决做到“两个维护”，为实现第二个百年奋斗目标、实现中华民族伟大复兴的中国梦作出更大贡献。\\n\\n校   训：精勤求学、敦笃励志、果毅力行、忠恕任事\\n\\n校   风：爱国爱校、追求真理、勤奋踏实、艰苦朴素\\n\\n办学定位：扎根西部、服务国家、世界一流\\n\\n西迁精神：\\n\\n核心：爱国主义\\n\\n精髓：听党指挥跟党走，与党和国家、与民族和人民同呼吸、共命运\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "!mkdir -p 'data/xianjiaoda/'\n",
    "!wget 'https://modelscope.oss-cn-beijing.aliyuncs.com/resource/rag/xianjiaoda.md' -O 'data/xianjiaoda/xianjiaoda.md'\n",
    "documents = SimpleDirectoryReader(\"/mnt/workspace/data/xianjiaoda/\").load_data()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac405d1-ea25-4656-95fa-550c33cfad8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:15:37.796015Z",
     "iopub.status.busy": "2024-11-12T17:15:37.795658Z",
     "iopub.status.idle": "2024-11-12T17:15:37.809515Z",
     "shell.execute_reply": "2024-11-12T17:15:37.808897Z",
     "shell.execute_reply.started": "2024-11-12T17:15:37.795994Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "embedding_model = \"iic/nlp_gte_sentence-embedding_chinese-base\"\n",
    "class ModelScopeEmbeddings4LlamaIndex(BaseEmbedding, ABC):\n",
    "    embed: Any = None\n",
    "    model_id: str = \"iic/nlp_gte_sentence-embedding_chinese-base\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_id: str,\n",
    "            **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        try:\n",
    "            from modelscope.models import Model\n",
    "            from modelscope.pipelines import pipeline\n",
    "            from modelscope.utils.constant import Tasks\n",
    "            # 使用modelscope的embedding模型（包含下载）\n",
    "            self.embed = pipeline(Tasks.sentence_embedding, model=self.model_id)\n",
    "\n",
    "        except ImportError as e:\n",
    "            raise ValueError(\n",
    "                \"Could not import some python packages.\" \"Please install it with `pip install modelscope`.\"\n",
    "            ) from e\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        text = query.replace(\"\\n\", \" \")\n",
    "        inputs = {\"source_sentence\": [text]}\n",
    "        return self.embed(input=inputs)['text_embedding'][0].tolist()\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        inputs = {\"source_sentence\": [text]}\n",
    "        return self.embed(input=inputs)['text_embedding'][0].tolist()\n",
    "\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        texts = list(map(lambda x: x.replace(\"\\n\", \" \"), texts))\n",
    "        inputs = {\"source_sentence\": texts}\n",
    "        return self.embed(input=inputs)['text_embedding'].tolist()\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "231dea19-6ffb-4f5b-8714-0fe29866af9a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-11-12T17:23:44.604776Z",
     "iopub.status.busy": "2024-11-12T17:23:44.604417Z",
     "iopub.status.idle": "2024-11-12T17:23:48.837351Z",
     "shell.execute_reply": "2024-11-12T17:23:48.836864Z",
     "shell.execute_reply.started": "2024-11-12T17:23:44.604757Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 01:23:45,346 - modelscope - WARNING - Model revision not specified, use revision: v1.1.0\n",
      "2024-11-13 01:23:45,716 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/hub/iic/nlp_gte_sentence-embedding_chinese-base\n",
      "2024-11-13 01:23:45,717 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/hub/iic/nlp_gte_sentence-embedding_chinese-base.\n",
      "2024-11-13 01:23:45,721 - modelscope - INFO - initialize model from /mnt/workspace/.cache/modelscope/hub/iic/nlp_gte_sentence-embedding_chinese-base\n",
      "2024-11-13 01:23:46,307 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-11-13 01:23:46,307 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-11-13 01:23:46,308 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/mnt/workspace/.cache/modelscope/hub/iic/nlp_gte_sentence-embedding_chinese-base'}. trying to build by task and model information.\n",
      "2024-11-13 01:23:46,345 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-11-13 01:23:46,346 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-11-13 01:23:46,346 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/mnt/workspace/.cache/modelscope/hub/iic/nlp_gte_sentence-embedding_chinese-base', 'sequence_length': 128}. trying to build by task and model information.\n",
      "/usr/local/lib/python3.10/site-packages/transformers/modeling_utils.py:1161: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.core import Settings\n",
    "# Configure the embeddings and LLM\n",
    "Settings.embed_model = ModelScopeEmbeddings4LlamaIndex(model_id=embedding_model)\n",
    "Settings.llm = llm\n",
    "\n",
    "# Create the index\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ecda8a3-1a55-45fb-814c-b66b50aac03a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-11-12T17:26:23.927685Z",
     "iopub.status.busy": "2024-11-12T17:26:23.927348Z",
     "iopub.status.idle": "2024-11-12T17:26:24.279611Z",
     "shell.execute_reply": "2024-11-12T17:26:24.279096Z",
     "shell.execute_reply.started": "2024-11-12T17:26:23.927665Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ACM International Collegiate Programming Contest\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"acm竞赛全称是什么\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
